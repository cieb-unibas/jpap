# pre-trained models:
# https://huggingface.co/papluca/xlm-roberta-base-language-detection
# => however: trained on 20 languages and not eng vs. rest. 
# Hence, train model from scratch using pytorch and check its perfromance.

### Datasets:
# Huggingface
# code as english vs. rest
# https://huggingface.co/datasets/papluca/language-identification

# Kaggle
# code as english vs. rest
# https://www.kaggle.com/datasets/basilb2s/language-detection
# https://www.kaggle.com/datasets/chazzer/big-language-detection-dataset

# WiLI
# https://paperswithcode.com/paper/the-wili-benchmark-dataset-for-written
# https://zenodo.org/record/841984

# SOTA > 0.98
